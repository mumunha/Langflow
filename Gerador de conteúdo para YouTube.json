{"id":"e2a91540-3c90-4333-be36-1548b43a09e4","data":{"nodes":[{"id":"CustomComponent-ACSgz","type":"genericNode","position":{"x":153,"y":140.25},"data":{"type":"YouTubeTranscriptExtractor","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, DropdownInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema.message import Message\r\nfrom youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\r\nimport re\r\n\r\nclass YouTubeTranscriptExtractor(Component):\r\n    display_name = \"YouTube Transcript Extractor\"\r\n    description = \"Extracts transcript from a YouTube video link.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_link\",\r\n            display_name=\"YouTube Link\",\r\n            info=\"Link to the YouTube video.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"language\",\r\n            display_name=\"Language\",\r\n            options=[\"en\", \"pt\", \"es\"],\r\n            info=\"Language for the transcript (en: English, pt: Brazilian Portuguese, es: Spanish).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Transcript\", name=\"transcript\", method=\"transcript_response\"),\r\n    ]\r\n\r\n    def transcript_response(self) -> Message:\r\n        youtube_link = self.youtube_link\r\n        language = self.language\r\n\r\n        video_id = self.extract_video_id(youtube_link)\r\n        \r\n        if video_id:\r\n            try:\r\n                transcript = self.get_transcript(video_id, language)\r\n                transcript_text = \" \".join([item['text'] for item in transcript])\r\n                message = Message(text=transcript_text)\r\n                self.status = transcript_text\r\n                return message\r\n            except Exception as e:\r\n                error_message = f\"Error: {str(e)}\"\r\n                self.status = error_message\r\n                return Message(text=error_message)\r\n        else:\r\n            error_message = \"Invalid YouTube link\"\r\n            self.status = error_message\r\n            return Message(text=error_message)\r\n\r\n    @staticmethod\r\n    def extract_video_id(link: str) -> str:\r\n        # Extract the video ID from the YouTube link\r\n        pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\r\n        match = re.search(pattern, link)\r\n        return match.group(1) if match else None\r\n\r\n    def get_transcript(self, video_id: str, language: str):\r\n        try:\r\n            return YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\r\n        except NoTranscriptFound:\r\n            return YouTubeTranscriptApi.get_transcript(video_id)  # Fallback to the default language if the specified language transcript is not found\r\n\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"language":{"trace_as_metadata":true,"options":["en","pt","es"],"required":false,"placeholder":"","show":true,"value":"pt","name":"language","display_name":"Language","advanced":false,"dynamic":false,"info":"Language for the transcript (en: English, pt: Brazilian Portuguese, es: Spanish).","title_case":false,"type":"str","load_from_db":false},"youtube_link":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_link","display_name":"YouTube Link","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Link to the YouTube video.","title_case":false,"type":"str"}},"description":"Extracts transcript from a YouTube video link.","icon":"youtube","base_classes":["Message"],"display_name":"Transcricao","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"transcript","display_name":"Transcript","method":"transcript_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["youtube_link","language"],"beta":false,"edited":true},"id":"CustomComponent-ACSgz","description":"Extracts transcript from a YouTube video link.","display_name":"Custom Component"},"selected":false,"width":384,"height":395,"positionAbsolute":{"x":153,"y":140.25},"dragging":false},{"id":"Prompt-M56k8","type":"genericNode","position":{"x":612,"y":142.25},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"Transcrição: {transcrição}\n\nBaseado na transcrição acima, crie três títulos e 3 descrições envolventes e informativas para vídeos do YouTube. Cada título deve ser cativante e otimizado para mecanismos de busca, enquanto as descrições devem ser detalhadas, incluindo palavras-chave relevantes, um breve resumo do conteúdo do vídeo e um chamado para ação.\n\n","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"transcrição":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcrição","display_name":"transcrição","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["transcrição"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":false,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-M56k8","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":423,"positionAbsolute":{"x":612,"y":142.25},"dragging":false},{"id":"YouTubeTranscriptExtractor-fwpOu","type":"genericNode","position":{"x":150.4267697963844,"y":800.06815237052},"data":{"type":"YouTubeTranscriptExtractor","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, DropdownInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema.message import Message\r\nfrom youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound\r\nimport re\r\n\r\nclass YouTubeTranscriptExtractor(Component):\r\n    display_name = \"YouTube Transcript Extractor\"\r\n    description = \"Extracts transcript from a YouTube video link.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_link\",\r\n            display_name=\"YouTube Link\",\r\n            info=\"Link to the YouTube video.\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"language\",\r\n            display_name=\"Language\",\r\n            options=[\"en\", \"pt\", \"es\"],\r\n            info=\"Language for the transcript (en: English, pt: Brazilian Portuguese, es: Spanish).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Transcript\", name=\"transcript\", method=\"transcript_response\"),\r\n    ]\r\n\r\n    def transcript_response(self) -> Message:\r\n        youtube_link = self.youtube_link\r\n        language = self.language\r\n\r\n        video_id = self.extract_video_id(youtube_link)\r\n        \r\n        if video_id:\r\n            try:\r\n                transcript = self.get_transcript(video_id, language)\r\n                transcript_text = self.format_transcript(transcript)\r\n                message = Message(text=transcript_text)\r\n                self.status = transcript_text\r\n                return message\r\n            except Exception as e:\r\n                error_message = f\"Error: {str(e)}\"\r\n                self.status = error_message\r\n                return Message(text=error_message)\r\n        else:\r\n            error_message = \"Invalid YouTube link\"\r\n            self.status = error_message\r\n            return Message(text=error_message)\r\n\r\n    @staticmethod\r\n    def extract_video_id(link: str) -> str:\r\n        # Extract the video ID from the YouTube link\r\n        pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\r\n        match = re.search(pattern, link)\r\n        return match.group(1) if match else None\r\n\r\n    def get_transcript(self, video_id: str, language: str):\r\n        try:\r\n            return YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\r\n        except NoTranscriptFound:\r\n            return YouTubeTranscriptApi.get_transcript(video_id)  # Fallback to the default language if the specified language transcript is not found\r\n\r\n    def format_transcript(self, transcript):\r\n        # Format the transcript with timestamps\r\n        formatted_transcript = \"\"\r\n        for item in transcript:\r\n            start = item['start']\r\n            text = item['text']\r\n            formatted_transcript += f\"[{self.format_time(start)}] {text}\\n\"\r\n        return formatted_transcript\r\n\r\n    @staticmethod\r\n    def format_time(seconds: float) -> str:\r\n        # Convert seconds to hh:mm:ss format\r\n        hours = int(seconds // 3600)\r\n        minutes = int((seconds % 3600) // 60)\r\n        seconds = int(seconds % 60)\r\n        return f\"{hours:02}:{minutes:02}:{seconds:02}\"\r\n\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"language":{"trace_as_metadata":true,"options":["en","pt","es"],"required":false,"placeholder":"","show":true,"value":"pt","name":"language","display_name":"Language","advanced":false,"dynamic":false,"info":"Language for the transcript (en: English, pt: Brazilian Portuguese, es: Spanish).","title_case":false,"type":"str","load_from_db":false},"youtube_link":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_link","display_name":"YouTube Link","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Link to the YouTube video.","title_case":false,"type":"str"}},"description":"Extracts transcript from a YouTube video link.","icon":"youtube","base_classes":["Message"],"display_name":"Transcricao time","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"transcript","display_name":"Transcript","method":"transcript_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["youtube_link","language"],"beta":false,"edited":true},"id":"YouTubeTranscriptExtractor-fwpOu","description":"Extracts transcript from a YouTube video link.","display_name":"Transcricao"},"selected":false,"width":384,"height":395,"positionAbsolute":{"x":150.4267697963844,"y":800.06815237052},"dragging":false},{"id":"AnthropicModel-ALMXj","type":"genericNode","position":{"x":1121,"y":144.25},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","anthropic_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_key","display_name":"Anthropic API Key","advanced":false,"input_types":[],"dynamic":false,"info":"Your Anthropic API key.","title_case":false,"password":true,"type":"str"},"anthropic_api_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_url","display_name":"Anthropic API URL","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":4096,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model":{"trace_as_metadata":true,"options":["claude-3-5-sonnet-20240620","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307"],"required":false,"placeholder":"","show":true,"value":"claude-3-5-sonnet-20240620","name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"https://python.langchain.com/docs/integrations/chat/anthropic","title_case":false,"type":"str"},"prefill":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"prefill","display_name":"Prefill","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Prefill text to guide the model's response.","title_case":false,"type":"str"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"0.3","name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generate text using Anthropic Chat&Completion LLMs with prefill support.","icon":"Anthropic","base_classes":["LanguageModel","Message"],"display_name":"Anthropic","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model","anthropic_api_key","temperature","anthropic_api_url","stream","system_message","prefill"],"beta":false,"edited":false},"id":"AnthropicModel-ALMXj"},"selected":false,"width":384,"height":651,"positionAbsolute":{"x":1121,"y":144.25},"dragging":false},{"id":"CustomComponent-I9Nce","type":"genericNode","position":{"x":629.3102188044522,"y":1465.7743957114553},"data":{"type":"TokenCountComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template import Output\r\nimport tiktoken\r\n\r\nclass TokenCountComponent(Component):\r\n    display_name = \"Token Count Component\"\r\n    description = \"Calculates the number of tokens in a given prompt.\"\r\n    icon = \"calculator\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"prompt\",\r\n            display_name=\"Prompt\",\r\n            info=\"The prompt text to count tokens for.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Token Count\", name=\"token_count\", method=\"count_tokens\"),\r\n    ]\r\n\r\n    def count_tokens(self) -> Message:\r\n        prompt = self.prompt\r\n        tokenizer = tiktoken.get_encoding(\"gpt2\")  # You can use other models' encoding as needed\r\n        token_count = len(tokenizer.encode(prompt))\r\n        \r\n        self.status = f\"Token Count: {token_count}\"\r\n        return Message(text=f\"Total de tokens na transcricao com timestamps: {token_count}\")","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"prompt":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"prompt","display_name":"Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The prompt text to count tokens for.","title_case":false,"type":"str"}},"description":"Calculates the number of tokens in a given prompt.","icon":"calculator","base_classes":["Message"],"display_name":"Tokens","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"token_count","display_name":"Token Count","method":"count_tokens","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["prompt"],"beta":false,"edited":true},"id":"CustomComponent-I9Nce","description":"Calculates the number of tokens in a given prompt.","display_name":"Tokens"},"selected":false,"width":384,"height":337,"dragging":false,"positionAbsolute":{"x":629.3102188044522,"y":1465.7743957114553}},{"id":"Prompt-Bzcp3","type":"genericNode","position":{"x":609.1540279792304,"y":-355.58449750610896},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"Transcrição:\n{transcrição}\n\nBaseado na transcrição anterior, elabore um prompt para geração de imagem utilizando a ferramenta DallE, sua resposta deve conter apenas o prompt e nada mais, nem uma palavra de introdução. O prompt deve ser em ingles.\n","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"transcrição":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcrição","display_name":"transcrição","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["transcrição"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":false,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-Bzcp3","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":423,"positionAbsolute":{"x":609.1540279792304,"y":-355.58449750610896},"dragging":false},{"id":"AnthropicModel-75kIo","type":"genericNode","position":{"x":1110.371337339584,"y":-607.8522896414283},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","anthropic_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_key","display_name":"Anthropic API Key","advanced":false,"input_types":[],"dynamic":false,"info":"Your Anthropic API key.","title_case":false,"password":true,"type":"str"},"anthropic_api_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_url","display_name":"Anthropic API URL","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":4096,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model":{"trace_as_metadata":true,"options":["claude-3-5-sonnet-20240620","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307"],"required":false,"placeholder":"","show":true,"value":"claude-3-5-sonnet-20240620","name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"https://python.langchain.com/docs/integrations/chat/anthropic","title_case":false,"type":"str"},"prefill":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"prefill","display_name":"Prefill","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Prefill text to guide the model's response.","title_case":false,"type":"str"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"0.3","name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generate text using Anthropic Chat&Completion LLMs with prefill support.","icon":"Anthropic","base_classes":["LanguageModel","Message"],"display_name":"Anthropic","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model","anthropic_api_key","temperature","anthropic_api_url","stream","system_message","prefill"],"beta":false,"edited":false},"id":"AnthropicModel-75kIo"},"selected":false,"width":384,"height":651,"positionAbsolute":{"x":1110.371337339584,"y":-607.8522896414283},"dragging":false},{"id":"Prompt-yMk2d","type":"genericNode","position":{"x":1592.367144311848,"y":-615.2489515696201},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"Create an image with a minimalistic style, without any text with the following context: {context}","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["context"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":false,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-yMk2d","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":423,"positionAbsolute":{"x":1592.367144311848,"y":-615.2489515696201},"dragging":false},{"id":"CustomComponent-jHBLo","type":"genericNode","position":{"x":2105.835308995523,"y":-616.3976499246169},"data":{"type":"DallEImageGenerator","node":{"template":{"_type":"Component","activate_image_generation":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"activate_image_generation","display_name":"Activate Image Generation","advanced":false,"dynamic":false,"info":"Toggle to activate or deactivate image generation.","title_case":false,"type":"bool"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, SecretStrInput, BoolInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema.message import Message\r\nfrom openai import OpenAI\r\n\r\nclass DallEImageGenerator(Component):\r\n    display_name = \"Dall-E Image Generator\"\r\n    description = \"Generates an image using the OpenAI Dall-E model from a text prompt.\"\r\n    icon = \"image\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"prompt\",\r\n            display_name=\"Text Prompt\",\r\n            info=\"Enter the text prompt to generate an image.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"openai_api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\r\n            advanced=False,\r\n            value=\"OPENAI_API_KEY\",\r\n        ),\r\n        BoolInput(\r\n            name=\"activate_image_generation\",\r\n            display_name=\"Activate Image Generation\",\r\n            info=\"Toggle to activate or deactivate image generation.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Generated Image\", name=\"generated_image\", method=\"generate_image\"),\r\n    ]\r\n\r\n    def generate_image(self) -> Message:\r\n        if not self.activate_image_generation:\r\n            self.status = \"Image generation is deactivated.\"\r\n            return Message(text=\"Image generation is deactivated.\")\r\n\r\n        prompt = self.prompt\r\n        openai_api_key = self.openai_api_key\r\n        client = OpenAI(api_key=openai_api_key)\r\n\r\n        try:\r\n            response = client.images.generate(\r\n                model=\"dall-e-3\",\r\n                prompt=prompt,\r\n                size=\"1792x1024\",\r\n                quality=\"standard\",\r\n                n=1,\r\n            )\r\n\r\n            image_url = response.data[0].url\r\n            self.status = f\"{image_url}\"\r\n            return Message(text=image_url)\r\n\r\n        except Exception as e:\r\n            error_message = f\"Failed to generate image: {str(e)}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"prompt":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"prompt","display_name":"Text Prompt","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Enter the text prompt to generate an image.","title_case":false,"type":"str"}},"description":"Generates an image using the OpenAI Dall-E model from a text prompt.","icon":"image","base_classes":["Message"],"display_name":"DallE Image","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"generated_image","display_name":"Generated Image","method":"generate_image","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["prompt","openai_api_key","activate_image_generation"],"beta":false,"edited":true},"id":"CustomComponent-jHBLo","description":"Generates an image using the OpenAI Dall-E model from a text prompt.","display_name":"Custom Component"},"selected":false,"width":384,"height":507,"positionAbsolute":{"x":2105.835308995523,"y":-616.3976499246169},"dragging":false},{"id":"CustomComponent-SDYrd","type":"genericNode","position":{"x":2608.965188484225,"y":-622.1411416996021},"data":{"type":"ImageDisplayComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nfrom langflow.schema.message import Message\r\nfrom typing import Optional\r\nimport requests\r\nfrom PIL import Image\r\nfrom io import BytesIO\r\nimport os\r\nimport mimetypes\r\nfrom datetime import datetime\r\n\r\nclass ImageDisplayComponent(Component):\r\n    display_name = \"Image Display\"\r\n    description = \"Displays an image from a given HTTP URL and saves it to the download folder.\"\r\n    icon = \"save\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"image_url\",\r\n            display_name=\"Image URL\",\r\n            info=\"URL of the image to display and save.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Image Data\", name=\"image_data\", method=\"fetch_image\"),\r\n    ]\r\n\r\n    def fetch_image(self) -> Message:\r\n        image_url = self.image_url\r\n\r\n        try:\r\n            response = requests.get(image_url)\r\n            response.raise_for_status()  # Raise an error on a bad status code\r\n            image = Image.open(BytesIO(response.content))\r\n\r\n            # Display the image\r\n            image.show()\r\n\r\n            # Save the image to the download folder\r\n            download_folder = os.path.expanduser(\"~/Downloads\")\r\n            if not os.path.exists(download_folder):\r\n                os.makedirs(download_folder)\r\n\r\n            # Determine the file extension\r\n            file_extension = os.path.splitext(image_url)[-1]\r\n            if not file_extension:\r\n                content_type = response.headers['Content-Type']\r\n                file_extension = mimetypes.guess_extension(content_type)\r\n\r\n            if not file_extension:\r\n                file_extension = '.png'  # Default to PNG if the extension cannot be determined\r\n\r\n            # Create a filename based on the current date and time\r\n            current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\r\n            file_name = f\"image_{current_time}{file_extension}\"\r\n            file_path = os.path.join(download_folder, file_name)\r\n            \r\n            image.save(file_path)\r\n\r\n            result = f\"Image displayed and saved to {file_path} successfully.\"\r\n        except Exception as e:\r\n            result = f\"Error displaying or saving image: {e}\"\r\n\r\n        self.status = result\r\n        return Message(text=result)\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"image_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"image_url","display_name":"Image URL","advanced":false,"input_types":["Message"],"dynamic":false,"info":"URL of the image to display and save.","title_case":false,"type":"str"}},"description":"Displays an image from a given HTTP URL and saves it to the download folder.","icon":"save","base_classes":["Message"],"display_name":"Salva e mostra","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"image_data","display_name":"Image Data","method":"fetch_image","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["image_url"],"beta":false,"edited":false},"id":"CustomComponent-SDYrd","description":"Displays an image from a given HTTP URL and saves it to the download folder.","display_name":"Custom Component"},"selected":false,"width":384,"height":337,"positionAbsolute":{"x":2608.965188484225,"y":-622.1411416996021},"dragging":false},{"id":"ChatInput-Kd78z","type":"genericNode","position":{"x":-581.0553818697423,"y":459.44161652980495},"data":{"type":"ChatInput","node":{"template":{"_type":"Component","files":{"trace_as_metadata":true,"file_path":"","fileTypes":["txt","md","mdx","csv","json","yaml","yml","xml","html","htm","pdf","docx","py","sh","sql","js","ts","tsx","jpg","jpeg","png","bmp","image"],"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"files","display_name":"Files","advanced":true,"dynamic":false,"info":"Files to be sent with the message.","title_case":false,"type":"file"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"User\",\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=\"User\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"https://www.youtube.com/watch?v=Vh45oRGmbuI","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as input.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"User","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"User","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"}},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["Message"],"display_name":"Chat Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true,"hidden":false}],"field_order":["input_value","sender","sender_name","session_id","files"],"beta":false,"edited":false},"id":"ChatInput-Kd78z"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":-581.0553818697423,"y":459.44161652980495},"dragging":false},{"id":"ChatOutput-Rk8ax","type":"genericNode","position":{"x":1720.2923939001375,"y":595.7462686296982},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-Rk8ax"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":1720.2923939001375,"y":595.7462686296982},"dragging":false},{"id":"ChatOutput-iLlW1","type":"genericNode","position":{"x":3203.6567093246285,"y":-420.71498445018597},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-iLlW1"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":3203.6567093246285,"y":-420.71498445018597},"dragging":false},{"id":"ChatOutput-sFKJb","type":"genericNode","position":{"x":1124.6073128836615,"y":1564.5607934318848},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-sFKJb"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":1124.6073128836615,"y":1564.5607934318848},"dragging":false},{"id":"Prompt-tm1pD","type":"genericNode","position":{"x":674.3628266141681,"y":865.3603583329898},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"Elabore uma lista de timestamps - formato HH:MM:SS (máximo de {max_timestamps}) timestamps com descrições bem resumidas com base nessa transcrição: \n{transcrição}","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"max_timestamps":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"8","fileTypes":[],"file_path":"","password":false,"name":"max_timestamps","display_name":"max_timestamps","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"transcrição":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcrição","display_name":"transcrição","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["max_timestamps","transcrição"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":false,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-tm1pD","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":517,"positionAbsolute":{"x":674.3628266141681,"y":865.3603583329898},"dragging":false},{"id":"AnthropicModel-IkzBo","type":"genericNode","position":{"x":1165,"y":834.2499999999997},"data":{"type":"AnthropicModel","node":{"template":{"_type":"Component","anthropic_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_key","display_name":"Anthropic API Key","advanced":false,"input_types":[],"dynamic":false,"info":"Your Anthropic API key.","title_case":false,"password":true,"type":"str"},"anthropic_api_url":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"anthropic_api_url","display_name":"Anthropic API URL","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_anthropic.chat_models import ChatAnthropic\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass AnthropicModelComponent(LCModelComponent):\n    display_name = \"Anthropic\"\n    description = \"Generate text using Anthropic Chat&Completion LLMs with prefill support.\"\n    icon = \"Anthropic\"\n    name = \"AnthropicModel\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            value=4096,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model Name\",\n            options=[\n                \"claude-3-5-sonnet-20240620\",\n                \"claude-3-opus-20240229\",\n                \"claude-3-sonnet-20240229\",\n                \"claude-3-haiku-20240307\",\n            ],\n            info=\"https://python.langchain.com/docs/integrations/chat/anthropic\",\n            value=\"claude-3-5-sonnet-20240620\",\n        ),\n        SecretStrInput(\n            name=\"anthropic_api_key\",\n            display_name=\"Anthropic API Key\",\n            info=\"Your Anthropic API key.\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        MessageTextInput(\n            name=\"anthropic_api_url\",\n            display_name=\"Anthropic API URL\",\n            advanced=True,\n            info=\"Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.\",\n        ),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True, value=False),\n        MessageTextInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"prefill\",\n            display_name=\"Prefill\",\n            info=\"Prefill text to guide the model's response.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        model = self.model\n        anthropic_api_key = self.anthropic_api_key\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        anthropic_api_url = self.anthropic_api_url or \"https://api.anthropic.com\"\n\n        try:\n            output = ChatAnthropic(\n                model=model,\n                anthropic_api_key=(SecretStr(anthropic_api_key) if anthropic_api_key else None),\n                max_tokens_to_sample=max_tokens,  # type: ignore\n                temperature=temperature,\n                anthropic_api_url=anthropic_api_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Anthropic API.\") from e\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, exception: Exception) -> str | None:\n        \"\"\"\n        Get a message from an Anthropic exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from anthropic import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(exception, BadRequestError):\n            message = exception.body.get(\"error\", {}).get(\"message\")  # type: ignore\n            if message:\n                return message\n        return None\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":4096,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model":{"trace_as_metadata":true,"options":["claude-3-5-sonnet-20240620","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307"],"required":false,"placeholder":"","show":true,"value":"claude-3-5-sonnet-20240620","name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"https://python.langchain.com/docs/integrations/chat/anthropic","title_case":false,"type":"str"},"prefill":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"prefill","display_name":"Prefill","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Prefill text to guide the model's response.","title_case":false,"type":"str"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"input_types":["Message"],"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"0.3","name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generate text using Anthropic Chat&Completion LLMs with prefill support.","icon":"Anthropic","base_classes":["LanguageModel","Message"],"display_name":"Anthropic","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true,"hidden":false},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model","anthropic_api_key","temperature","anthropic_api_url","stream","system_message","prefill"],"beta":false,"edited":false},"id":"AnthropicModel-IkzBo"},"selected":false,"width":384,"height":651,"positionAbsolute":{"x":1165,"y":834.2499999999997},"dragging":false},{"id":"ChatOutput-ZQHLD","type":"genericNode","position":{"x":1694.2923939001375,"y":1233.746268629698},"data":{"type":"ChatOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.chat import ChatComponent\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[\"Machine\", \"User\"],\n            value=\"Machine\",\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\", display_name=\"Sender Name\", info=\"Name of the sender.\", value=\"AI\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"session_id\", display_name=\"Session ID\", info=\"Session ID for the message.\", advanced=True\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and isinstance(message.text, str):\n            self.store_message(message)\n            self.message.value = message\n\n        self.status = message\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"data_template":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{text}","name":"data_template","display_name":"Data Template","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.","title_case":false,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Message to be passed as output.","title_case":false,"type":"str"},"sender":{"trace_as_metadata":true,"options":["Machine","User"],"required":false,"placeholder":"","show":true,"value":"Machine","name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"Type of sender.","title_case":false,"type":"str"},"sender_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"AI","name":"sender_name","display_name":"Sender Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Name of the sender.","title_case":false,"type":"str"},"session_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"session_id","display_name":"Session ID","advanced":true,"input_types":["Message"],"dynamic":false,"info":"Session ID for the message.","title_case":false,"type":"str"}},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["Message"],"display_name":"Chat Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"message","display_name":"Message","method":"message_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","sender","sender_name","session_id","data_template"],"beta":false,"edited":false},"id":"ChatOutput-ZQHLD"},"selected":false,"width":384,"height":309,"positionAbsolute":{"x":1694.2923939001375,"y":1233.746268629698},"dragging":false}],"edges":[{"source":"CustomComponent-ACSgz","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œCustomComponent-ACSgzœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-M56k8","targetHandle":"{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-M56k8œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcrição","id":"Prompt-M56k8","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"YouTubeTranscriptExtractor","id":"CustomComponent-ACSgz","name":"transcript","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-ACSgz{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œCustomComponent-ACSgzœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}-Prompt-M56k8{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-M56k8œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-M56k8","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-M56k8œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"AnthropicModel-ALMXj","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-ALMXjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AnthropicModel-ALMXj","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-M56k8","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-M56k8{œdataTypeœ:œPromptœ,œidœ:œPrompt-M56k8œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-ALMXj{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-ALMXjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"YouTubeTranscriptExtractor-fwpOu","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-I9Nce","targetHandle":"{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-I9Nceœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"prompt","id":"CustomComponent-I9Nce","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"YouTubeTranscriptExtractor","id":"YouTubeTranscriptExtractor-fwpOu","name":"transcript","output_types":["Message"]}},"id":"reactflow__edge-YouTubeTranscriptExtractor-fwpOu{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-I9Nce{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-I9Nceœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-ACSgz","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œCustomComponent-ACSgzœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-Bzcp3","targetHandle":"{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-Bzcp3œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcrição","id":"Prompt-Bzcp3","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"YouTubeTranscriptExtractor","id":"CustomComponent-ACSgz","name":"transcript","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-ACSgz{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œCustomComponent-ACSgzœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}-Prompt-Bzcp3{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-Bzcp3œ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-Bzcp3","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-Bzcp3œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"AnthropicModel-75kIo","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-75kIoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AnthropicModel-75kIo","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-Bzcp3","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-Bzcp3{œdataTypeœ:œPromptœ,œidœ:œPrompt-Bzcp3œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-75kIo{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-75kIoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"AnthropicModel-75kIo","sourceHandle":"{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-75kIoœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-yMk2d","targetHandle":"{œfieldNameœ:œcontextœ,œidœ:œPrompt-yMk2dœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"context","id":"Prompt-yMk2d","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"AnthropicModel","id":"AnthropicModel-75kIo","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-AnthropicModel-75kIo{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-75kIoœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt-yMk2d{œfieldNameœ:œcontextœ,œidœ:œPrompt-yMk2dœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-yMk2d","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-yMk2dœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-jHBLo","targetHandle":"{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-jHBLoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"prompt","id":"CustomComponent-jHBLo","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-yMk2d","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-yMk2d{œdataTypeœ:œPromptœ,œidœ:œPrompt-yMk2dœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-jHBLo{œfieldNameœ:œpromptœ,œidœ:œCustomComponent-jHBLoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-jHBLo","sourceHandle":"{œdataTypeœ:œDallEImageGeneratorœ,œidœ:œCustomComponent-jHBLoœ,œnameœ:œgenerated_imageœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-SDYrd","targetHandle":"{œfieldNameœ:œimage_urlœ,œidœ:œCustomComponent-SDYrdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"image_url","id":"CustomComponent-SDYrd","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"DallEImageGenerator","id":"CustomComponent-jHBLo","name":"generated_image","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-jHBLo{œdataTypeœ:œDallEImageGeneratorœ,œidœ:œCustomComponent-jHBLoœ,œnameœ:œgenerated_imageœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-SDYrd{œfieldNameœ:œimage_urlœ,œidœ:œCustomComponent-SDYrdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"ChatInput-Kd78z","sourceHandle":"{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Kd78zœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}","target":"YouTubeTranscriptExtractor-fwpOu","targetHandle":"{œfieldNameœ:œyoutube_linkœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_link","id":"YouTubeTranscriptExtractor-fwpOu","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-Kd78z","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-Kd78z{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Kd78zœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-YouTubeTranscriptExtractor-fwpOu{œfieldNameœ:œyoutube_linkœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"AnthropicModel-ALMXj","sourceHandle":"{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-ALMXjœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-Rk8ax","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Rk8axœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-Rk8ax","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"AnthropicModel","id":"AnthropicModel-ALMXj","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-AnthropicModel-ALMXj{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-ALMXjœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Rk8ax{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Rk8axœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-SDYrd","sourceHandle":"{œdataTypeœ:œImageDisplayComponentœ,œidœ:œCustomComponent-SDYrdœ,œnameœ:œimage_dataœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-iLlW1","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-iLlW1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-iLlW1","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ImageDisplayComponent","id":"CustomComponent-SDYrd","name":"image_data","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-SDYrd{œdataTypeœ:œImageDisplayComponentœ,œidœ:œCustomComponent-SDYrdœ,œnameœ:œimage_dataœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-iLlW1{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-iLlW1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-I9Nce","sourceHandle":"{œdataTypeœ:œTokenCountComponentœ,œidœ:œCustomComponent-I9Nceœ,œnameœ:œtoken_countœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-sFKJb","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sFKJbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-sFKJb","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TokenCountComponent","id":"CustomComponent-I9Nce","name":"token_count","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-I9Nce{œdataTypeœ:œTokenCountComponentœ,œidœ:œCustomComponent-I9Nceœ,œnameœ:œtoken_countœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-sFKJb{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-sFKJbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"YouTubeTranscriptExtractor-fwpOu","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-tm1pD","targetHandle":"{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-tm1pDœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcrição","id":"Prompt-tm1pD","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"YouTubeTranscriptExtractor","id":"YouTubeTranscriptExtractor-fwpOu","name":"transcript","output_types":["Message"]}},"id":"reactflow__edge-YouTubeTranscriptExtractor-fwpOu{œdataTypeœ:œYouTubeTranscriptExtractorœ,œidœ:œYouTubeTranscriptExtractor-fwpOuœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œMessageœ]}-Prompt-tm1pD{œfieldNameœ:œtranscriçãoœ,œidœ:œPrompt-tm1pDœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-tm1pD","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-tm1pDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"AnthropicModel-IkzBo","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-IkzBoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"AnthropicModel-IkzBo","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-tm1pD","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-tm1pD{œdataTypeœ:œPromptœ,œidœ:œPrompt-tm1pDœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-AnthropicModel-IkzBo{œfieldNameœ:œinput_valueœ,œidœ:œAnthropicModel-IkzBoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"AnthropicModel-IkzBo","sourceHandle":"{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-IkzBoœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"ChatOutput-ZQHLD","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZQHLDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-ZQHLD","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"AnthropicModel","id":"AnthropicModel-IkzBo","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-AnthropicModel-IkzBo{œdataTypeœ:œAnthropicModelœ,œidœ:œAnthropicModel-IkzBoœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-ZQHLD{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-ZQHLDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"ChatInput-Kd78z","sourceHandle":"{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Kd78zœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-ACSgz","targetHandle":"{œfieldNameœ:œyoutube_linkœ,œidœ:œCustomComponent-ACSgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_link","id":"CustomComponent-ACSgz","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ChatInput","id":"ChatInput-Kd78z","name":"message","output_types":["Message"]}},"id":"reactflow__edge-ChatInput-Kd78z{œdataTypeœ:œChatInputœ,œidœ:œChatInput-Kd78zœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-ACSgz{œfieldNameœ:œyoutube_linkœ,œidœ:œCustomComponent-ACSgzœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":314.60328133743434,"y":271.8747411446606,"zoom":0.3298769776932238}},"description":"Fluxo criado por techmumus\nhttps://www.youtube.com/@techmumus6780\nEsse fluxo recebe um link de vídeo, extrai a transcrição e cria:\n- 3 opções de título\n- 3 opções de descrição\n- lista de timestamps\n- thumbnail\n\nDesenvolvido no Langflow 1.0.7","name":"Gerador de conteúdo para YouTube","last_tested_version":"1.0.7","endpoint_name":null,"is_component":false}